{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CD-VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIHc2tzvLh3IlJU4/rsSTy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvinas/CIBERSORT/blob/master/CD_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olwORgMViS-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "17df97bc-3aee-4c73-c448-64c16576954b"
      },
      "source": [
        "!pip install tensorflow-probability==0.8.0rc0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-probability==0.8.0rc0 in /usr/local/lib/python3.6/dist-packages (0.8.0rc0)\n",
            "Requirement already satisfied: cloudpickle==1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.8.0rc0) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.8.0rc0) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.8.0rc0) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.8.0rc0) (4.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VvzzlXO939_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "2635bfc9-1fbb-47cf-eeb5-727a5729a32b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\"\"\"\n",
        "from tensorflow.python import tf2\n",
        "if not tf2.enabled():\n",
        "    import tensorflow.compat.v2 as tf\n",
        "    tf.enable_v2_behavior()\n",
        "    assert tf2.enabled()\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "tfpl = tfp.layers\n",
        "tfd = tfp.distributions\n",
        "\n",
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "    print('WARNING: GPU device not found.')\n",
        "else:\n",
        "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "SUCCESS: Found GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmRrl_pO9_lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCN(tfkl.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(GCN, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        bs, nb_vars, dim = input_shape[0]\n",
        "\n",
        "        self.w = self.add_weight(shape=(dim, self.units),\n",
        "                              initializer='random_normal',\n",
        "                              trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                             initializer='random_normal',\n",
        "                             trainable=True)\n",
        "        super(GCN, self).build(input_shape)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        h, adj = inputs\n",
        "\n",
        "        # Compute normalized adjacency matrix\n",
        "        nb_vars = adj.shape[0]\n",
        "        adj_hat = adj + tf.linalg.diag(tf.ones(nb_vars))\n",
        "        d_hat = tf.reduce_sum(adj_hat, axis=-1)  # Degree of each variable\n",
        "        d_hat_sqrt = tf.linalg.diag(tf.sqrt(d_hat))\n",
        "        norm_adj_hat = d_hat_sqrt @ adj_hat @ d_hat_sqrt\n",
        "\n",
        "        # Perform graph convolutions\n",
        "        h_t = tf.transpose(h, perm=(0, 2, 1))  # (bs, dim, nb_vars)\n",
        "        norm_adj_hat_t = tf.transpose(norm_adj_hat, perm=(1, 0))  # Shape=(nb_vars, nb_vars)\n",
        "        out = tf.transpose(h_t @ norm_adj_hat_t, perm=((0, 2, 1))) @ self.w + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "class Encoder(tfkl.Layer):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.loc = tfkl.Dense(nb_vars)\n",
        "        self.scale = tfkl.Dense(nb_vars, activation=tf.nn.softplus)\n",
        "        self._trainable_weights = [self.loc.trainable_weights, self.scale.trainable_weights]\n",
        "        super(Encoder, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        return tfd.MultivariateNormalDiag(self.loc(x),\n",
        "                                          self.scale(x))\n",
        "\n",
        "class Decoder(tfkl.Layer):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Input shape: (bs, nb_vars)\n",
        "        bs, nb_vars = input_shape\n",
        "        p = self.add_weight(shape=(nb_vars, nb_vars),\n",
        "                            initializer=lambda shape, dtype: tf.ones(shape, dtype=dtype)/2,\n",
        "                            trainable=True)\n",
        "        mask = 1 - tf.linalg.diag(tf.ones(nb_vars))\n",
        "        self.p = p * mask\n",
        "        self.f = GCN(2)\n",
        "        super(Decoder, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, temperature = 0.2):\n",
        "        a = tfd.RelaxedBernoulli(temperature, probs=self.p).sample()\n",
        "        e = x[..., None]  # Noise terms for each variable. Shape=(bs, nb_vars, 1) \n",
        "        h = self.f([e, a])  # Shape=(bs, nb_vars, 2)\n",
        "        loc = h[..., 0]\n",
        "        scale = h[..., 1]\n",
        "        out = tfd.MultivariateNormalDiag(loc, scale)\n",
        "        return out\n",
        "\n",
        "def _encoder(x, nb_vars):\n",
        "    # x = tfkl.Input((nb_vars,))\n",
        "    loc = tfkl.Dense(nb_vars)(x)\n",
        "    scale = tfkl.Dense(nb_vars, activation=tf.nn.softplus)(x)\n",
        "    z = tfd.MultivariateNormalDiag(loc, scale)\n",
        "    # Consider using a tfpl.IndependentNormal distribution, since noise terms are assumed to be independent\n",
        "    return z\n",
        "\n",
        "def prior(nb_vars):\n",
        "    loc = tf.zeros(nb_vars)\n",
        "    scale = tf.ones(nb_vars)\n",
        "    return tfd.MultivariateNormalDiag(loc, scale)\n",
        "\n",
        "def _decoder(z, nb_vars, temperature = 0.2):\n",
        "    # Sample adjacency matrix\n",
        "    p = tf.Variable([[0.5] * nb_vars] * nb_vars)  # Probability of edge between pairs of variables\n",
        "    mask = 1 - tf.linalg.diag(tf.ones(nb_vars))\n",
        "    p = p * mask\n",
        "    a = tfd.RelaxedBernoulli(temperature, probs=p)\n",
        "\n",
        "    # Define GNN\n",
        "    e = z[..., None]  # Noise terms for each variable. Shape=(bs, nb_vars, 1) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42iLMNLmL-ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "d254e1bd-cd9c-480a-a4f9-19528bbe937e"
      },
      "source": [
        "nb_vars = 10\n",
        "x_ = tf.placeholder(tf.float32, [None, nb_vars])\n",
        "encoder = Encoder()(x_)  # Posterior approximation\n",
        "code = encoder.sample()\n",
        "decoder = Decoder()(code)\n",
        "\n",
        "likelihood = decoder.log_prob(x_)\n",
        "divergence = tfd.kl_divergence(encoder, prior(nb_vars))\n",
        "elbo = tf.reduce_mean(likelihood - divergence)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0XTLHTORAgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "7ccb714e-c875-4d0c-949b-f9dcd61ebb69"
      },
      "source": [
        "optimize = tf.train.AdamOptimizer(0.001).minimize(-elbo)\n",
        "\n",
        "x = np.ones((32, nb_vars))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoch in range(20):\n",
        "        _, loss = sess.run([optimize, -elbo], {x_: x})\n",
        "        print('Epoch: {}, loss: {}'.format(epoch, loss))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 24643.818359375\n",
            "Epoch: 1, loss: 127284.0859375\n",
            "Epoch: 2, loss: 61146.0625\n",
            "Epoch: 3, loss: 72896.46875\n",
            "Epoch: 4, loss: 2335.203125\n",
            "Epoch: 5, loss: 4472.8916015625\n",
            "Epoch: 6, loss: 61876.86328125\n",
            "Epoch: 7, loss: 5953.37841796875\n",
            "Epoch: 8, loss: 2421.377685546875\n",
            "Epoch: 9, loss: 263428.09375\n",
            "Epoch: 10, loss: 1043436.3125\n",
            "Epoch: 11, loss: 178079.8125\n",
            "Epoch: 12, loss: 7622.06640625\n",
            "Epoch: 13, loss: 7755.15185546875\n",
            "Epoch: 14, loss: 5827.3466796875\n",
            "Epoch: 15, loss: 3505.302001953125\n",
            "Epoch: 16, loss: 14061.1181640625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-73b734ed08c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}, loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye7ufQJF_4Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature = 0.2\n",
        "nb_vars = 2\n",
        "p = tf.Variable([[0.5] * nb_vars] * nb_vars)\n",
        "dist = tfd.RelaxedBernoulli(temperature, probs=p)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}